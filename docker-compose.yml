services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: paperless
      POSTGRES_USER: test
      POSTGRES_PASSWORD: paper
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U test -d paperless"]
      interval: 5s
      timeout: 3s
      retries: 10
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbit
    environment:
      RABBITMQ_DEFAULT_USER: user
      RABBITMQ_DEFAULT_PASS: pass
    ports:
      - "5672:5672"     # AMQP
      - "15672:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 5s
      timeout: 3s
      retries: 10
    restart: unless-stopped

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - ELASTIC_PASSWORD=changeme
      - xpack.security.enabled=false  # deaktiviert HTTPS/Security (nur lokal)
      - http.host=0.0.0.0
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -u elastic:changeme -f http://localhost:9200"]
      interval: 10s
      retries: 10
      timeout: 5s
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/paperless
      SPRING_DATASOURCE_USERNAME: test
      SPRING_DATASOURCE_PASSWORD: paper
      SPRING_RABBITMQ_HOST: rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      SPRING_RABBITMQ_USERNAME: user
      SPRING_RABBITMQ_PASSWORD: pass
      # optional sinnvoll:
      # SPRING_JPA_HIBERNATE_DDL_AUTO: update
      # SERVER_PORT: 8081
      ELASTIC_HOST: http://elasticsearch:9200
      ELASTIC_USER: elastic
      ELASTIC_PASS: changeme
    depends_on:
      postgres:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    expose:
      - "8081"           # intern für die UI/NGINX
    ports:
      - "8081:8081"      # optional: nur für direkten Zugriff/Debug buw für npm run dev (beim Frontend)
    restart: unless-stopped

  ocr-worker:
    build:
      context: ./ocr-worker
      dockerfile: Dockerfile
    environment:
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: user
      RABBITMQ_PASS: pass
      QUEUE_NAME: ocr.jobs
      RESULT_QUEUE: ocr.results
      ELASTIC_HOST: http://elasticsearch:9200
      ELASTIC_USER: elastic
      ELASTIC_PASS: changeme
    depends_on:
      rabbitmq:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    ports:
      - "8082:8082"   # falls du eine einfache Health/Info-HTTP-Route im Worker willst (optional)
    restart: unless-stopped

  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    ports:
      - "80:80"        # Browser: http://localhost:80 oder garnichts
    depends_on:
      - backend
    restart: unless-stopped

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9090:9090"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9090"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  genai-worker:
    build:
      context: ./genai-worker
    env_file:
      - .env
    environment:
      RABBITMQ_HOST: rabbitmq
      RABBITMQ_PORT: 5672
      RABBITMQ_USER: user
      RABBITMQ_PASS: pass
      GENAI_INPUT_QUEUE: ocr.results # konsumiert die OCR-Ergebnisse
      GENAI_OUTPUT_QUEUE: genai.results
      GENAI_MODEL: ${GENAI_MODEL:-gemini-2.5-flash}
      # GEMINI_API_KEY kommt aus .env
    depends_on:
      rabbitmq:
        condition: service_healthy
      backend:
        condition: service_started
    restart: unless-stopped

  accesslog-batch:
    build:
      context: ./accesslog-batch
      dockerfile: Dockerfile
    environment:
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/paperless
      SPRING_DATASOURCE_USERNAME: test
      SPRING_DATASOURCE_PASSWORD: paper

      ACCESSLOG_INPUT_DIR: /opt/batch/in
      ACCESSLOG_ARCHIVE_DIR: /opt/batch/archive
      ACCESSLOG_ERROR_DIR: /opt/batch/error
      ACCESSLOG_FILE_PATTERN: "access-*.xml"
      ACCESSLOG_CRON: "0/30 * * * * *"   # alle 30 Sekunden für Debug -> "0 0 1 * * *" wäre täglich um 1 Uhr
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./accesslogs/in:/opt/batch/in
      - ./accesslogs/archive:/opt/batch/archive
      - ./accesslogs/error:/opt/batch/error
    restart: unless-stopped


volumes:
  pgdata:
  es_data:
  rabbitmq_data:
  minio_data:
